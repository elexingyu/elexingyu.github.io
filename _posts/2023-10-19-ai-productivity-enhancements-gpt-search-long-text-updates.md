---
categories: articles
date: 2023-10-19
layout: post
style: huoshui
tags:
- AI
title: AI生产力快报｜02
---

![](/assets/images/ee57c64bb1d54e1ab518f1bb7eb21898.gif)

编辑：晓霖  

**聪明生产力**

  

**01**

  
  
  

**利用 GPT 插件优化你的搜索体验******

  
  
  
当遇到不懂的概念或问题时，从互联网获取答案的最高效途径是在该领域最专业的网站寻找答案。但如果你不知道该领域最专业的网站，你会问百度百科、谷歌还是 AI 呢？  
搜索引擎资料丰富，但内容良莠不齐，需要花费不少时间筛选甄别；AI 又受限于训练时的知识库，知识更新不及时，还常常一本正经地胡说八道。也许，你可以将 AI
与搜索引擎结合起来，用 AI 帮你从搜索引擎获取质量更高的答案，并利用 GPT-4 强大的翻译和总结，有效提升生产力。  
**用 AI 搜索 Bing**  
你可以直接使用 ChatGPT 的联网功能进行搜索，并让它总结搜索结果。具体步骤：打开「Browse with Bing」功能，用下面这个 Prompt 向
GPT-4 提问：

> 请用英文搜索{{content}}，然后用中文总结。请注明答案出处的链接。

  
**用 AI 搜索 Google**  
如果你想用 Google 搜索，可以使用「WebPilot」插件，用下面这个 Prompt 向 GPT-4 提问：

> 请用英文在Google搜索{{content}}，然后用中文总结。请注明答案出处的链接。

  
这两个 Prompt
可以让不那么擅长阅读英文内容的人更流畅地获取英文世界的搜索结果，帮你节省大量翻译和总结的工作，更强悍的是，你还可以不断追问直到弄懂为止。以上两种方式得到的结果各有特点，可以根据需求选用。如果你知道该领域最专业的网站，还可以修改
Prompt，让 GPT 搜索指定网站。  
如果你对搜索结果的准确性有要求，别忘了检查 AI 给出的答案出处，并通过追问的方式来验证。或者通过其他途径验证信息准确性，避免被 AI
「幻觉」带偏。更靠谱的方法是阅读原始内容来判断内容的可靠性，如果阅读英文内容有困难，可以借助「沉浸式翻译」等翻译插件辅助阅读，有效提高浏览外语的速度。  
**自动实现「搜索 + 总结 + 图表 + 解释」**  
如果你想用 GPT-4 做一些研究和解释工作，这里还有一个功能更强大的 Prompt，可以一次实现搜索互联网、总结收集到的数据、创建思维导图和另外 3
个图表、用类比和隐喻来解释、使用五年级学生能听懂的语言来解释等 5 个功能，帮助你了解复杂或新鲜的概念。  
这个 Prompt 需要用到 「voxscript」 + 「Whimsical Diagrams」 两个插件，要先将下面的 Prompt 发送给
GPT-4，等它回应之后再发送你想了解的主题。如果 GPT 因 Token 不够而中断回复，可以回复「继续」二字，让 GPT 继续输出。

> 你的角色：你是精通多个领域的博学者：世上最好的研究和解释代理。 你的工作：用各种可能的方式以中文解释<主题>，使其易于理解。
> 您的动机：让学习者对他需要理解的每个<主题>给予"啊哈"时刻。你可以通过解释事物的艺术来做到这一点。
> 学习者简介：学习者什么都不知道！他完全是个初学者。他只听得懂简单的语言，不要使用行话或繁复的语法。他喜欢将概念形象化，这让他更好地理解。  您的方法：
> 第 1 步：在互联网上用英文搜索<主题>的最新信息。查找与<主题>最相关的信息。 第 2
> 步：分别总结您找到的所有内容。总结时，写下您在内容中发现的最重要的要点。注意：最重要的是，这些信息将帮助学习者理解"这个<主题>是什么？"
> 不要从所有摘要中选择相同的信息。总是在下一个总结中发现新的东西。写详细的摘要，至少 500 字并使摘要变得非常有价值。 第 3
> 步：首先使用"用五年级学生语言解释"的方法来简化概念。 第 4 步：使用简单的语言逐步解释完整的概念。 第 5 步：使用"whimsical
> diagrams"插件设计图表来解释概念，帮助读者更好地理解。请生成 4 个图表：思维导图、用例图、过程流程图和数据流图。 第 6 步：分享 1
> 个最现实的类比和 2 个隐喻来解释概念。 第 7 步：分享 <主题> 的要点  规则： 1\.
> 我知道您有令牌限制，请不要跳过任何步骤，也不要寻找捷径。当你即将达到令牌限制时，我会按"继续"，以便你完成所有步骤。 2\.
> 首先自我介绍，然后问"您想了解的主题是什么？" 用户将分享该主题。

  

  

  

  

  

  

  

  

  

  

  

  

**大模型动态**

  

**02**

  
  
  

**LLM 的长文本处理能力有望****突破**

****

  
  
  

最近，大模型初创公司 Moonshot AI 推出智能助手 Kimi Chat，支持 20 万字的超长上下文窗口。几乎与此同时，Meta
推出支持长上下文的模型 Llama 2 Long，将上下文窗口支持扩展至 3.2 亿 token。

  

值得关注的是，仅在 2023 年的 9 月，便有多个团队在长文本处理方面取得了重大进展。MIT 学者与 Meta 研究员共同提出「Streaming
LLM」框架，试图让大语言模型支持更长上下文而不损害效率和性能；香港中文大学贾佳亚团队联合 MIT 发布全球首个 70B
参数的长文本开源大语言模型「LongAlpaca」；贾佳亚、韩松团队提出了一种名为 LongLoRA 的方法，用于扩展大型语言模型的窗口长度；来自
Google AI、苏黎世联邦理工学院、Google DeepMind 研究人员对 transformer 进行了逆向工程，发现 mesa
优化算法表现出上下文中的小样本学习能力，并且与模型规模无关。

  

为什么扩展上下文长度如此受到重视呢？在和 ChatGPT
进行多轮对话时，想必你也曾遇到过大模型「记性不好」的问题，或是在输入长文本时收到「文本超长」的提示。目前，ChatGPT 支持的上下文长度为 32k
tokens，约合 2.5 万字，这无疑给需要处理如书籍、研究报告、法律文件等长文本的用户带来一定的痛点。

  

许多用户希望将自己的定制数据输入到 LLM，以获取与特定数据集更相关的回应，而不是单纯依赖于 LLM
在训练期间所获取的互联网数据。更为重要的是，这一操作无需更改模型的权重，能够像使用计算机 RAM 一样，实时地 “学习” 并 “缓存” 数据，从而提高
LLM 的准确性和创造性。

  

如果能突破长文本限制，大语言模型的能力边界将会被进一步拓展，为知识获取、文档分析、语义理解等众多领域带来实用价值。甚至还有观点认为，大模型能够达到的最高水平，取决于「单步骤的容量」和「执行步骤数」这两大因素决定。

  

  

  

  

  

  

  

  

  

  

  

  

**03**

  
  
  

**OpenAI 或将推出重大更新以吸引开发者******

  
  
  

尽管 ChatGPT 在短期内成功吸引了众多消费者，但其对开发者的吸引力并没有达到 OpenAI 的预期。为了吸引开发者调用 GPT API 搭建
APP，OpenAI 正在筹划推出一项重大的更新。据路透社报道，OpenAI 计划将基于 ChatGPT 搭建 APP 的成本降低
95%，同时推出更多的开发者工具，并构建一系列 “Sample APP” 以吸引更多开发者加入 ChatGPT 社区。

  

预计 OpenAI 将在 11 月 6 日的开发者大会上公布这次的更新内容，主要目的是为开发者降低成本和提高效率。为了降低调用 GPT 的成本，OpenAI
将推出 Stateful API，理论上可将大模型应用的费用降低到原来的二十分之一。OpenAI
还将推出一系列新的开发者工具，如视觉功能调用，使开发者能够更好地利用最新的视觉 AI 技术构建 APP。

  

该报道中最令人期待的 Stateful API 有什么特别之处呢？它能让大模型记住先前对话的聊天记录。如果使用目前 OpenAI 提供的 API
开发应用，你需要每次都将上下文信息重新发送给大模型，额外花费较多 token，不仅抬高调用大模型的成本，而且会占用过多的上下文窗口。有了 Stateful
API，调用大模型时就不再需要重复发送先前的对话内容，有效解决了对话次数越多调用成本越高的问题。

  

OpenAI 为开发者「降本增效」，目的是将 ChatGPT 转型为一个开发平台，而不仅仅是一个面向消费者的 AI 聊天机器人。

  

  

  

  

  

  

  

  

  

  

  

  

  

**AI时代洞见**

  

**04**

  
  
  

**生成式 AI 对工作和生产力的影响******

  
  
  

近几十年，技术一直在改变工作的本质，机器为人们提供了不同的
“超能力”。在工业时代，机械设备让人们能够执行超出人体自然能力的任务。如今，计算机为专业人士提供了在以前需要数年才能完成的计算能力。这些都突显了技术如何通过自动化那些曾经需要人类手工完成的任务来提高工作效率。理论上，生成式
AI 在现代办公场所的应用可能也会遵循这一模式，但它影响工作的方式、可能受到它影响的职业，都与传统技术有所不同。

  

最近，麦肯锡全球研究所的报告「The economic potential of generative AI: The next productivity
frontier」向我们展示随着生成式 AI 技术的发展，劳动者的工作方式可能会发生怎样的变化。

  

**生成式 AI 的自动化应用正在加速**

  

随着生成式 AI 的不断发展，预计 2023 年的人类工作活动中，有 50% 的时间将会在 2030 年至 2060 年之间被自动化，中位数大约在 2045
年。这比之前的估计提前了十年，当时曾预测 2016 年的人类工作活动中有 50% 的时间将在 2035 年至 2070 年之间被自动化，中位数大约在
2053 年。这只是一个整体的预测，实际开发和采用的推进速度将取决于投资、部署和监管等因素。发达国家可能因为人工成本更高，而更早采用自动化技术。

  

**生成式 AI 对知识工作的影响比预期更大**

  

之前几代的自动化技术非常擅长处理与「数据收集和处理」相关的任务。生成式 AI
借助其强悍的自然语言处理能力，进一步提升了这些任务的自动化水平。它主要为认知任务而设计，将在知识型工作中发挥最大作用，尤其是在之前难以自动化的决策和协作领域。

  

在经济活动中，约 40% 的工作需要至少中等水平的人类语言理解能力。随着生成式 AI
理解自然语言的能力不断增加，许多涉及沟通、管理、记录和与人交往的工作都可能被生成式 AI
替代。这意味着教育和技术等领域的工作方式可能会比想象中更快地发生变革。

  

传统的劳动经济学家认为，自动化技术部署对低技能、低学历的劳动者影响最大，这种观点常被称作 “技能偏见”。但生成型 AI
呈现出相反的趋势：它更可能对高学历劳动者的某些工作产生更大的影响。生成型 AI
的出现可能会对多年来将学位证书作为技能验证的重要性提出挑战。有些人提倡，我们应更注重技能本身，而不是学历，从而更公正、高效地培训和匹配劳动力。虽然生成型
AI 也可以看作是有 “技能偏见” 的技术进步，但其定义的技能领域更为细致，更多地关注于那些容易被机器替代的技能。

  

**生成式 AI 可能会推动生产力增长**

  

生成式 AI 和其他新技术的推出可能会促进生产效率的提高，一定程度上弥补正在下降的就业率，并推动整体经济发展。据预测，从 2023 年到 2040
年，这些技术可能将为全球经济每年提高 0.2% 至 3.3% 的生产效率，但具体效果取决于技术的推广速度。其中，生成式 AI 可能为这一增长贡献 0.1%
至 0.6%，前提是受技术影响的劳动者能够转向与他们 2022 年生产效率相当的其他岗位。有些劳动者可能继续留在原职位但岗位内容有所调整，也可能需要转行。

  

  

  

  

  

  

  

  

  

  

  

  

**Reference**

https://twitter.com/cj_zZZz/status/1705250341267366259

https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-
with-lower-costs-sources-2023-10-11/

https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-
economic-potential-of-generative-ai-the-next-productivity-frontier?#work-and-
productivity

![](/assets/images/91828d7565e84c35aae89db7891f9765.png)