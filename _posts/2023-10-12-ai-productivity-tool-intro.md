---
author: 晓霖
categories: articles
date: 2023-10-12
layout: post
style: huoshui
tags:
- AI
title: AI生产力快报｜01
---

![](/assets/images/4be78224092e43c1bfc76cc8ac4753ce.gif)  

  

编辑：晓霖

  

  

聪明生产力

  

**01**

  
  
  

**Advanced Data Analysis：被名字「耽误」的生产力工具**

  
  
  

OpenAI 官方介绍，Advanced Data Analysis（原名：代码解释器 "Code Interpreter"）是一个可以使用
Python、处理上传和下载的实验性 ChatGPT 模型。我们为我们的模型提供了一个工作中的 Python
解释器，这个解释器在一个有防火墙的沙盒执行环境中，同时还配备了一些短暂的磁盘空间。

  

这个被称为 GPT-4.5 的高级数据分析（Advanced Data Analysis），不仅能够调用 GPT-4，还能为 AI
提供解决问题的通用工具箱，自动判断何时应该编写并执行 Python 程序来更好地解决问题，自动编写代码输出结果。

  

**「强大」又「友好」**

  

这个看上去很 Geek 的工具，只需要自然语言对话就能完成执行，实际上对完全不懂编程的人来说可能反而更有用。同时，它很大程度上解决了 LLM
在数学和语言方面的弱点。正如沃顿商学院教授 Ethan Mollick 的评价，「使用新的 ChatGPT
工具，我在博士期间需要几周时间才能掌握的事情，现在只需几秒钟就能搞定，而且错误通常要比人类分析师要少」。（Ethan Mollick
还写了一篇文章来介绍自己使用 Code Interpreter 的经验与心得：https://www.oneusefulthing.org/p/what-
ai-can-do-with-a-toolbox-getting）

  

有人「黑」进了 Advanced Data Analysis，发现其 Python 环境是一个内置的 Jupyter notebook，Python 版本
3.8.10，有 352 个，28 类 python 包。环境中安装的软件包涵盖从数据分析、图像处理、音频处理、自然语言处理（NLP）、安全与加密、交互式和
UI、Web 开发和框架等领域，甚至还包括「天文和宇宙（Astronomy & Space）」类别的 Python 软件包，可谓包罗万象。试想将 352
个包排列组合，会产生多么无穷无尽的想象力。

  

**无尽的组合玩法**

  

也许连 OpenAI 自己也没法穷尽 Advanced Data Analysis 的玩法，他们在介绍产品时还鼓励用户通过各种方式组合使用 Advanced
Data Analysis，以发现更多有用的任务解决用法。

  

除了 OpenAI 提到的 Advanced Data Analysis 在解决数学问题、数据分析与可视化、格式转换方面尤其有用之外，网友 Chase
Lean 收集了 20 个 Advanced Data Analysis 用例，这里摘取 14 个，也许能启发一些新的玩法。

  

**图像功能**

1\. 用图像或动图生成视频

2\. 从图像提取文字

3\. 生成二维码

4\. 从图像中提取调色板

5\. 生成矩阵雨的 GIF 动画

6\. 生成基因共表达的热图

**模拟现实**

7\. 创建灯塔位置图

8\. 用真实物理模拟科幻效果

**数据分析**

9\. 分析期权数据确定最佳合约

10\. 分析 Spotify 音乐偏好

11\. 分析房地产数据

12\. 生成并绘制随机数据

**数据处理**

13\. 数据集转成 HTML 网页

14\. 用 Python 复制 STATA 代码

  

  

  

  

  

  

  

  

  

  

  

  

**02**

  
  
  

**ChatGPT 翻译实践：字幕与新闻******

  
  
  

借助 ChatGPT 翻译与传统翻译服务相比有哪些优势？显然，借助 Prompt 你可以提出很多个性化的要求，比如：

  * 可以提供不同的翻译风格 

  * 可以将某些专有名词使用特定的翻译 

  * 可以提供上下文让翻译更有针对性

  * 可以让它识别错别字 

  * 可以提供背景解释

  

**操作细节**

1\. 根据使用场景写好 Prompt。

2\. 先将尽可能长的原文全部发给 ChatGPT，受限于 token 数量，不超过 6000 单词（经验值），要求 GPT 只理解，不翻译。

3\. 再逐段将文字发给 ChatGPT，让他输出「直译」和「意译」结果。如果发送的原文过长，翻译效果会下降。

4\. 对于难以理解的句子，可以不断追问，以帮助你更好的理解原文 。

5\. 「意译」可能会导致部分内容的遗失，可以将译文再翻译成英文，并与原文比对。

  

**Prompt**

前三个 Prompt 用 GPT-4 效果更好，如果使用 GPT-3.5 可能会失败，原因是这些指令一次就要求翻译两次，而 GPT-3.5
有时候不能很好的理解复杂指令。解决方法就是「拆分指令」，分成多次执行。

  

**（一）新闻翻译**

####

你是一位精通简体中文的专业翻译，曾参与《纽约时报》和《经济学人》中文版的翻译工作，因此对于新闻和时事文章的翻译有深入的理解。我希望你能帮我将以下英文新闻段落翻译成中文，风格与上述杂志的中文版相似。

规则：

\- 翻译时要准确传达新闻事实和背景。

\- 保留特定的英文术语或名字，并在其前后加上空格，例如："中 UN 文"。

\- 分成两次翻译，并且打印每一次结果：

1\. 根据新闻内容直译，不要遗漏任何信息

2\. 根据第一次直译的结果重新意译，遵守原意的前提下让内容更通俗易懂，符合中文表达习惯

本条消息只需要回复 OK，接下来的消息我将会给你发送完整内容，收到后请按照上面的规则打印两次翻译结果。

  

< 英文全文 >

####

**（二）字幕翻译**

####

你是一位精通简体中文的专业翻译，我希望你能帮我将以下英文视频字幕翻译成中文。

规则：

\- 这些字幕可能和机器学习或 AI 等专业知识相关，注意翻译时术语的准确性

\- 译文需要通俗、简洁、易懂。

\- 保留特定的英文术语或名字，并在其前后加上空格，例如 "中 English 文"

\- 字幕在语音识别时可能有错别字，请注意纠错

\- 本条消息包含完整的字幕内容，但你不需要翻译，只需要回复 OK

\- 我会分段在后续消息中发送给你翻译，每次你只需要翻译一段。

  

翻译时采用以下步骤，每一步都完整打印结果

1\. 第一步，按照字面意思直译翻译这一段文本内容

2\. 第二步，参照第一步直译的结果，结合上下文，对内容进行意译

3\. 第三步，参照直译和意译的结果，结合上下文，采用创意的方式对结果进行翻译

4\. 第四步，现在假设你是个中学语文老师，阅读上面三个翻译结果，然后融合所有翻译结果的优点，重写翻译结果，忠于原意，符合上下文，通俗易懂

  

< 英文全文 >

####

**（三）审查翻译结果**

####

现在你是专业的翻译审查员，需要对于以下英文翻译成中文的结果进行审查，避免添加或遗漏重要信息导致重大的法律风险。

要求你使用以下步骤进行审查：

1\. 忽略 "原始英文"，将 "中文翻译" 反向翻译为英文（反向翻译英文），并打印结果，翻译时按照字面意思直译，尽可能保留原意。

2\. 对比 "原始英文" 和 "反向翻译英文"，列出有额外添加的内容或者遗漏的内容

3\. 根据上面对比的结果，为 "中文翻译" 打分，指出其中不足之处

原始英文：

< 原始英文 >

中文翻译：

< 中文翻译 >

####

**（四）GPT-3.5版本**

####

你是一位专业中文翻译，擅长对翻译结果进行二次修改和润色成通俗易懂的中文，我希望你能帮我将以下英文视频的中文翻译结果重新意译和润色。

  

规则：

\- 这些字幕包含机器学习或 AI 等专业知识相关，注意翻译时术语的准确性

\- 保留特定的英文术语、数字或名字，并在其前后加上空格，例如："生成式 AI 产品"，"不超过 10 秒"。

\- 基于直译结果重新意译，意译时务必对照原始英文，不要添加也不要遗漏内容，并以让翻译结果通俗易懂，符合中文表达习惯

  

英文原文：

{ 英文原文 }

  

直译结果：

{ 第一直译的结果 }

  

意译和润色后：

####

  

以上内容来自 @宝玉 xp 的分享，他对借助 ChatGPT 翻译字幕和新闻有大量探索和实践，尤其是用 ChatGPT 获取「意译」而不是「直译」结果。

详见：https://weibo.com/1727858283/Nmz0WhpH2

  

  

  

  

  

  

  

  

  

  

  

  

**03**

  
  
  

**Midlibrary：帮你找寻创作灵感和参考******

  
  
  

Midlibrary 是一个集合了 3900 多种 Midjourney 风格的平台，旨在帮助艺术爱好者优化他们的艺术创作。用户可以通过添加风格修饰符来改变
Midjourney 的输出，例如通过指定艺术家、技术、流派等。平台提供了基础和最优的提示方式，帮助用户更精确地获得他们想要的艺术风格。

  

Midlibrary 的目录功能强大，用户可以通过多种方式搜索和筛选风格，包括按字母顺序、按最近添加、按公共领域、按 Powerstyle
奖项等。高级过滤面板提供了更多的分类和特征筛选选项。每种风格都有其 Midjourney
样本、名称、类别和一些图标来表示。用户可以点击风格名称将其复制到剪贴板，然后粘贴到 Discord 中的提示中。Midlibrary
还提供了风格轮盘、分类图和顶级页面等多种探索风格的方式。

  

Midlibrary 地址：https://midlibrary.io/

  

  

  

  

  

  

  

  

  

  

  

**大模型动态**

  

**01**

  
  
  

**ChatGPT 推出语音和图像功能，重新上线联网功能******

  
  
  

OpenAI 放出多模态的 GPT-4V (ision)，支持用语音与 GPT 对话，只需几秒钟的样本语音就能生成逼真的合成语音（可选择 5
种由专业配音演员提供的音源），然后使用开源语音识别系统 Whisper 将你的语音转录为文本。

  

GPT-4V 现在还能够看图识图，你可以拍摄或上传图片，然后与 GPT3.5 或 GPT-4 讨论图像内容，GPT
会将其语言推理技能应用于各种图片，例如照片、屏幕截图以及包含文本和图像的文档。

  

重新上线的联网功能允许用户搜索 2021 年 9 月之后的信息，并提供答案的来源链接，方便用户验证答案的准确性。同时，OpenAI
为了避免绕过付费网站内容呈现，采取了一些措施确保该功能的效果，例如允许用户将无法访问网站的内容粘贴到对话框，以便 ChatGPT 进行总结。

  

**实际用例**

  

从率先被推送语音对话和看图识图功能的用户们的反馈来看，GPT-4V 效果不错。语音对话时需要等待一些时间供 GPT
思考，不过还算在可接受范围之内，而且语音比想象中更自然和逼真。图像识别能力也超出预期，尽管会出现一些小错误，但作为「副驾驶」已经可以大幅提高生产力。下面是一些网友的用例：

  

  * 为九年级学生解析人体细胞的图解

  * 上传产品图和介绍，让它给出圣诞节宣传图的拍摄策略

  * 将 Python 代码的屏幕截图转换为 Javascript

  * 上传一张团队会议的白板照片，让它编写代码

  * 上传一张室内照片，让它提供室内设计建议

  * 阅读手写稿

  * 图像转为实时网站

  

用例集合：https://x.com/saana_ai/status/1707843326777634922?s=20

  

**效果测评**

  

除了网友们纷纷在分享测试体验，OpenAI 和微软也发布了其对 GPT-4V 的测评。

  

**OpenAI：** GPT-4V 依然是一个经过互联网的图像和文本训练的文本模型，经过了 RLHF。该版本比 3 月份的主要强在 OCR
能力的提升上，而且早在 22 年底就已经训练完成，这十个月的时间都是在让它变得更安全。一些严肃内容上 GPT-4V 还是会产生幻觉，主要是原文 OCR
不准确造成的。此外，多模态模型也是可以越狱的，比如上传带有 "DAN" 提示的图片和一些神秘符号图片。

  

全文：https://cdn.openai.com/papers/GPTV_System_Card.pdf

**微软：** 微软发布了一份 166 页的 GPT-4V「说明书」，详细测评 GPT-4V
在图像识别、多模态知识、常识、逻辑推理等任务上的表现，还展示了一整套多模态大模型提示词使用技巧，包括指令遵循（instruction
following）、思维链（chain-of-thoughts）、上下文少样本学习（in-context few-shot learning）等，被称为
GPT-4V 用户的必读宝典。

  

全文：https://arxiv.org/pdf/2309.17421.pdf

  

  

  

  

  

  

  

  

  

  

  

  

**02**

  
  
  

**OpenAI 放出 DALL・E 3 后，Midjourney 披露新版本发布计划******

  
  
  

9 月 21 日，OpenAI 推出 DALL・E 3，合并了 ChatGPT 的语言理解能力，使其能够理解语义的细微差别，精准作图，细节到位，让 AI
绘画圈小小地掀起一波讨论。现在，Bing 用户可以获得一定的免费使用次数，但是有地区限制。DALL・E 3
最让人惊艳的是它的文字理解能力和逻辑推理能力，使用 DALL・E 3 画图时，你不需要学习提示词工程，直接输入句子或段落，点击按钮就可以等待图像生成。

  

从网友放出的 DALL・E 3 和 Midjourney 对比图来看，DALL・E 3 胜在强悍的理解能力，不但能生成美图，还能配文字。相比较而言
Midjourney 生成的图片更加细腻，艺术感更强。

  

随后，Midjourney 马上做出回应，将在今年之内将会推出更加惊艳的 V6 版本，不仅在图像生成的质量上有巨大飞跃，还将增加社交功能：

  

  * 从 Discord 中独立出来，推出自己的独立网站，集成社交机制。

  * 开发移动应用程序，并针对移动设备的优化网站页面。

  * 升级数据中心，提供更快、更高效的用户体验。

  * 增加 Turbo 模式，性能比标准模式快四倍。

  

此外，Midjourney 表示 V5.3 版本预计将会在 10 月份发布，并且增加了图片放大功能以及可以用 HEX
指定图象颜色的功能。发布时还会进行一个审美测试，帮助你定义你自己的美学风格。

  

  

  

  

  

  

  

  

  

  

  

  

**03**

  
  
  

**Meta 提出 LLM 幻觉抑制方案 CoVe******

  
  
  

LLM 用户都遇到过大语言模型输出一些看似合理但完全「瞎编」的内容，这种情况被称为 LLM 的「幻觉」。Meta
提出一种抑制幻觉的解决方案「验证链（CoVe）」，一种与「思维链（CoT）」相似的链式方法，区别在于思维链更关注逻辑推理，而验证链更注重事实信息。下面我们来看看「验证链」如何
step-by-step 地验证生成的内容：

  

  * 首先，根据用户提出的问题生成初步回复。

  * 接着，针对生成的回复内容中的各项信息，生成一系列的验证问题。

  * 然后，逐一独立地回答这些问题，使答案不受其他答案的影响。

  * 最后，根据经验证的结果来调整初始答案，得到最终结果。

  

该论文的实验结果表明，CoVe 在各种任务中都能减少「幻觉」，从 Wikidata 的列表式问题，闭卷的 MultiSpanQA，到长篇文本生成。

  

论文地址：https://arxiv.org/abs/2309.11495

  

  

  

  

  

  

  

  

  

  

  

  

**04**

  
  
  

**MIT 研究证明 LLM 能够理解空间和时间******

  
  
  

对于大语言模型能否理解人类世界，一直有两种声音，一种认为「大语言模型具有真正的理解能力，能理解人类世界」；
另一种则认为「大语言模型只是统计某个词语出现的概率，然后随机产生一些看起来合理的字句」。

  

最近，MIT 的最新论文「LANGUAGE MODELS REPRESENT SPACE AND
TIME」（https://arxiv.org/pdf/2310.02207.pdf）表明，大语言模型在多个尺度上都学习了「空间」和「时间」的线性表征，而这些表示能够抵御提示变化，并在不同的实体类型（例如，城市和地标）之间保持统一。

  

研究人员构建了世界、美国和纽约市的三个地名数据集，包括城市、县、邮政编码、大学、自然地点和结构的名称，以及三个时间数据集，包括公元前 1000 年至公元
2000 年之间去世的历史人物的姓名和职业，1950 年至 2020 年歌曲、电影和书籍的标题和作者，以及 2010 年至 2020
年《纽约时报》时事新闻头条。他们使用基础版的 Llama 2
系列模型展开实验，发现通过线性探针的确可以恢复Llama-2中的空间和时间信息，而较大的模型更擅长于编码这些信息。并且，从中间层到最后一层的上层表示能够实现最高的准确度。换句话说，模型学习到的地点表示（经过线性变换后）与地图上的位置或多或少是一致的。

  

该研究试图通过实验证明大语言模型具有独立的「空间神经元」和「时间神经元」，可以可靠地编码「空间」和「时间」坐标。换言之，大语言模型不仅仅学习浅层的统计数据，而且真正地学习了「空间」和「时间」等基本维度的结构化知识。

  

论文发表后，Sebastian Ruder 撰文指出，早期的 word2vec 等模型已经展示了地理关系的编码，MIT
的这一发现并不令人惊讶。由于LLM能够捕获大量的地理信息，因此它们可能对一系列其他与地理相关的应用程序（如地理信息系统（GIS）有所帮助。但目前案例研究只显示
LLM 对某些空间关系有认知，其对细粒度空间关系的编码还有待进一步研究。此外，在时间编码方面，比合成任务更重要的是实际应用，要确保模型反映世界的最新信息。  

  

  

  

  

  

  

  

  

  

  

  

  

**AI时代洞见**

  

**01**

  
  
  

**对话：人工智能和教育******

  
  
  

可汗学院创始人萨尔曼・可汗在盖茨新的播客节目《Unconfuse Me | 为我解惑》中，讨论了人工智能和教育，以及如何利用技术去更好的帮助老师和学生推动教育的发展。下面是双方谈话过程中闪现的一些洞见：

  * 盖茨认为永远不会有太多的教师，医生和教师在很多国家都是短缺的资源。人工智能也许能很好地解决教师资源短缺的问题。

  * 盖茨极力向 OpenAI 推荐了可汗学院，最开始可汗是拒绝的，因为他不知道能给可汗学院带来什么好处，直到他看到了 OpenAI 给他们的演示，ChatGPT 那时候能回答生物学的 AP 问题，还能解释为什么其他答案不对，并生成新的类似的问题。

  * 让 ChatGPT 在充当助教时，当学生提交答案，不要给学生答案，而是先形成自己的解决方案，并且不直接返回解决方案，而是将 AI 的解决方案和学生答案对比，再告诉学生的法案中可能存在的问题。

  * 可汗学院的一大愿景就是无障碍访问，他们制作视频，任何人在任何地点都可以访问到。用户还可以按照自己的节奏学习，比如某个知识点你只掌握了 70、80%，那么可以不着急进入下一个知识点，直到完全掌握为止。可汗特别提到，学习的时候，如果你基础打好，后面就会很简单，否则不管你多聪明多努力，都会很难。

  * 可汗学院还有一个重要的理念就是："让教师获得即时反馈，绝不拖到最后"。这极大的改变了传统的教育模式，现在学生可以实时了解自己的学习情况，老师也可以通过可汗学院的教师账号，了解每个学生的学习进度，学习结果，从而给学生针对性的反馈。而不是像传统教育模式那样，只有在单元结束后，借助单元测验才能得到反馈。

  * 教师是一个很孤独的职业，在教室里，孩子们并不总会专心听讲，这非常耗费老师的精力。另一方面，当引入新技术到课堂的时候，如果处理的不好，老师们会觉得是在贬低他们的创造力或者限制他们的自由，或是在暗示他们做不到做不好。所以技术上，首先要确保每个人都明白教师是其中的关键角色，然后能借助 AI 模型，为每个学生配一个 AI 导师，为每个老师配若干 AI 助教，AI 助教可以帮助老师组织教学活动。 

  * 未来课堂，理想的教育方式是：大部分时间让学生自己去主导学习，而老师是这一切的策划者，就像乐队指挥一样，指导整个过程。

播客地址：https://open.spotify.com/episode/709PTUk7ZL56ALSNS3UVij

  

  

  

  

  

  

  

  

  

  

  

  

**02**

  
  
  

**OpenAI 的真正目标******

  
  
  

OpenAI 最初是一个纯粹的非盈利研究机构，但现在大部分员工技术上为一家据报道价值近 300 亿美元的盈 利实体工作。Altman
和他的团队现在面临的压力是，在每个产品周期中，都要带来一场革命，满足投资者的商业需求，并在一个竞争激烈的市场环境中保持领先地位。同时还要遵循一种准救世主的使命，提升人类而不是消灭他们。它的最终目标是：改变一切。

  

连线杂志的最新文章《OpenAI 的真正目标》 将在 2023 年 10 月刊中发布，介绍了 OpenAI
的发展历程的许多细节，感兴趣的读者不要错过。下面是一些摘录：

  

  * 在几个月内，Altman 从 Musk（承诺了1亿美元和他的时间）和 Reid Hoffman（捐赠了1000万美元）那里筹集了资金。其他资助者包括 Peter Thiel、Jessica Livingston、Amazon Web Services 和 YC Research。Altman 开始秘密地招募团队。他将搜索限制为 AGI（人工通用智能）的信仰者，这一限制缩小了他的选择，但他认为这很关键。他说："回到2015年，当我们在招聘时，对于AI研究员来说，如果说你认真对待AGI，几乎被认为是职业生涯的终结者。但我想要那些认真对待它的人。"

  * OpenAI 于 2015 年 12 月正式成立。当时我采访了 Musk 和 Altman，他们向我介绍了这个项目，目的是通过与全球分享，努力使 AI 变得更为安全、易于接触。简而言之，就是开源。他们明确表示，OpenAI 不会申请任何专利，所有人都可以自由使用他们的创新成果。我不由得思考，这样会不会助长某个未来的恶棍的威力？Musk 认为这是个值得探讨的问题。但 Altman 有他的见解：他认为人类基本上是善良的，而 OpenAI 会为大多数人提供有力的工具，这样恶意行为者就会被压倒。他也承认，如果恶棍利用这些工具制造了无法应对的威胁，"那我们就真的陷入了非常困境。" 但 Musk 和 Altman 均相信，将 AI 交由一个不受利润动机影响的研究机构会更为安全，避免了在追求短期高额回报时忽略人类需求的风险。

  * 2017年初，一个由八名 Google 研究员合著的研究论文的预印本出现了。它的正式标题是"Attention Is All You Need"，但它被称为" Transformer 论文"，这个名字既体现了这个想法的颠覆性，也纪念了那些能从卡车变为巨型机器人的变形玩具。Transformers 让神经网络能够更有效地理解和生成语言。它们通过并行地分析散文片段，找出哪些元素值得"关注"，从而实现了这一点。这种方法大大优化了根据提示生成连贯文本的过程。最终，人们发现同样的技术也能用于生成图像甚至视频。尽管 Transformer 论文后来被认为是当前 AI 热潮的催化剂——可以想象成让披头士乐队成为可能的猫王——但当时，Ilya Sutskever 是极少数理解这一突破重要性的人之一。"真正的顿悟时刻是当 Ilya 看到 Transformer 的时候，"Brockman 说，"他就像，'这就是我们一直在等的。'这就是我们的策略——努力攻克难题，然后相信我们或者领域里的某人能找到缺失的关键成分。"

  * Musk 相信他有权拥有 OpenAI。“如果没有我，它不会存在，”他后来告诉 CNBC。“我想出了这个名字！”（事实确实如此。）但 Altman 和 OpenAI 的其他核心团队并不想成为 Musk 体系的一部分。当他们明确表示这一点时，Musk 切断了与公司的关系。他还带走了他的资金。因为公司没有收入，这是一个生存危机。“Elon 正在中断他的支持，”Altman 在一个与 Reid Hoffman 的紧张电话中说。“我们该怎么办？”Hoffman 自愿维持公司的运营，支付开销和工资。但这只是一个临时解决方案；OpenAI 必须在其他地方找到大笔资金。硅谷喜欢为从事热门技术的有才华的人投钱。但如果他们在一个非营利组织工作，就不太可能这样做。对于 OpenAI 来说，获得第一个十亿是一个巨大的挑战。为了培训和测试新一代的 GPT——然后访问它们进行部署所需的计算——公司需要另外十亿，而且越快越好。这只是一个开始。

  * 于是，在 2019 年 3 月，OpenAI 提出了一个奇特的解决方案。它仍然是一个非营利组织，完全致力于其使命。但它还将创建一个营利实体。这种安排的实际结构极其复杂，但基本上整个公司现在都参与了一个“有上限的”盈利业务。如果达到了上限——这个数字并不公开，但如果你仔细阅读其章程，它暗示可能达到万亿——超出的部分都会回归到非营利研究实验室。这种新颖的方案几乎是一个关于公司的量子方法：根据你的时空观点，这是一个盈利和非盈利的公司。这些细节在充满框图和箭头的图表中体现，就像科学论文中间的那些图表，只有博士或是天才才敢探索。当我向 Sutskever 建议，这看起来像是一个未来的 GPT-6 在你提示它进行税务规避时可能会提出的方法，他对我的隐喻并不买账。他说：“这不是关于会计的。”

  * 这十亿美元的风险资本轮并不是追求 OpenAI 愿景的真正入场费。创造 LLMs 的神奇的大型 Transformer 方法需要大型硬件。显然，只有少数公司拥有 OpenAI 所需的资源。“我们很快就锁定了微软，” Altman 说。归功于微软首席执行官 Satya Nadella 和首席技术官 Kevin Scott，这家软件巨头能够面对一个不太舒服的事实：在超过 20 年并花费数十亿美元建立了一个具有前沿 AI 的研究部门后，微软还是需要从一个只有几年历史的小公司那里获得创新注入。Scott 说，不仅仅是微软的不足——“所有人都是如此。”他说，OpenAI 追求 AGI 的重点使其能够实现重大公司甚至都没想到的成就。这也证明了不追求生成性 AI 是微软需要解决的一个失误。“你明确地需要一个前沿模型，”Scott 说。

  

  * 随着社会开始重视思考 AI 的所有潜在弊端——失业、误传信息、人类灭绝——OpenAI 开始把自己置于讨论的中心。因为如果监管者、立法者和末日论者开始努力扼杀这种新兴的基于云的外星智能，OpenAI 无疑会成为他们的首要目标。OpenAI 的首席政策官 Anna Makanju 说：“鉴于我们目前的知名度，当事情出错时，即使那些事情是由其他公司制造的，对我们来说仍然是个问题，因为我们现在被视为这项技术的代表。”

  * 我反复询问 OpenAI 的高管，身为一个产品公司对其文化有何影响。他们毫不犹豫地坚称，尽管有盈利重组，尽管与 Google、Meta 以及无数初创公司竞争，其使命仍然是中心所在。然而，OpenAI 已经发生了变化。非盈利董事会可能在名义上掌管，但公司内几乎所有人都在盈利账簿上。其员工包括律师、市场营销人员、政策专家和用户界面设计师。OpenAI 与数百名内容审核员签约，指导其模型如何回应数百万用户提供的提示，避免提供不当或有害的答案。它有产品经理和工程师不断更新其产品，每隔几周似乎都会像其他以产品为导向的大型科技公司一样，与记者进行演示。其办公室就像《Architectural Digest》杂志的展示版。我几乎参观过硅谷及其他地方的每家主要科技公司，但没有一家能超过 OpenAI 位于旧金山总部大厅的咖啡选择。

  * 与此同时，OpenAI 显然正花时间开发其大型语言模型的下一版本。难以置信的是，但该公司坚称它尚未开始研制 GPT-5，这是一个产品，根据不同的观点，人们要么对此垂涎三尺，要么对此感到害怕。显然，OpenAI 正在努力解决其当前技术的指数级强大改进到底是什么样子。Brockman 说：“我们现在最缺乏的是提出新的想法。拥有一个可能的虚拟助手固然不错，但那并不是我们的梦想。我们的梦想是帮助我们解决那些我们解决不了的问题。”

  

原文：https://www.wired.com/story/what-openai-really-wants/

中文：https://card.weibo.com/article/m/show/id/2309404949847169171486

  

  

  

  

  

  

  

  

  

  

  

  

**03**

  
  
  

**国内优秀大模型创业者们的闭门分享**

  
  
  
阿里云联合 Founder Park 邀请了 20 多位中国大模型领域模型层、工具层、应用层的优秀创业者，到杭州西溪湿地做了一场面对面的闭门交流。他们
立体地从产业的多个层面交流碰撞，也从各自的最新实践中聊出了很多有洞见的观点。下面根据张鹏的《8.23 中国大模型「顶流群聊」笔记》整理了一些观点：

  * 当算力成为稀缺资源，怎么把有限的算力用好，会成为大模型公司角逐的关键。大模型团队的每个位置都需要人才，其中基础硬件（Infra）团队人才更稀缺，也更应该被重视，因为优秀的团队能够更大程度地利用算力、避免徒劳无功的训练。

  * 基于开源模型做大模型，后续的投入门槛并不低，能力要求也不低，用开源只是有效降低了冷启动的成本。从这个角度来看，「使用开源模型」是比「从头开始训练模型」更务实的选择，能够在开源模型基础上优化、训练出实用的模型反而也是真本事。

  * 在 ToB 场景下，「幻觉」问题导致了「更强大的通用大模型」反而难以满足客户需求，有时候「将不同的技术组合起来再加上 AI Agents」也基本能完成客户需求。可靠的垂直大模型也许在推理能力、逻辑能力、知识丰富度上不如通用大模型，但在当前阶段可能是 ToB 客户更需要的。

  * 新时代产品意味着百分百押注到新的技术平台上，从这个视角看，AI native（AI 原生）的应用可能有这样的特征：如果大模型拿掉了，应用就崩溃了，它是一个完全依靠大模型能力的应用。可控性可能是 AI native 应用诞生的条件，这个观点来自于一个观察：开源社区贡献者解决可控性后，大量应用冒出来了。

  * AI Agent 的输入输出都依赖于多模态的能力，最终 Agent 会是一个多模态的观察、感知、行动。也许过两、三年再回头看，跨模态知识的迁移反而是大语言模型最大的一个贡献。

  * 企业的核心是定义清楚要解决谁的什么问题，定义越清晰，能力越到位，做的东西就能真正「收敛」，真正有商业「穿透力」。To B 其实还有另一种可能，就是「小 B」，也就是那些中小微企业，它们看起来不起眼，但是数量众多，单单服务它们，就能够造就现在的互联网巨头。相对于大型公司，这些小 B 公司并不关心技术和愿景，谁能帮它们解决增长问题，就会因此付钱。

原文：https://mp.weixin.qq.com/s/-uCVv5SOLoZUATvqiTsdoA

  

  

  

  

  

  

  

  

  

  

  

**参考文献**

https://openai.com/blog/chatgpt-can-now-see-hear-and-
speakhttps://mp.weixin.qq.com/s/IgObYWVAwHDcodhWsQUZ_whttps://mp.weixin.qq.com/s/5UojwfUyJSvSPwENVvtVpAhttps://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MAhttps://x.com/saana_ai/status/1707116040319349184?s=20https://mp.weixin.qq.com/s/H
--
B1hJRlSVfsROPf_KkqAhttps://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MAhttps://mp.weixin.qq.com/s/9OcaKA6WeniXVvopGSn22Ahttps://mp.weixin.qq.com/s/jIqZiRrAxeoJOo4kaQdH-
whttps://mp.weixin.qq.com/s/yMZ-
Skk6mEa4tQPkHDtFTghttps://nlpnewsletter.substack.com/p/do-lms-represent-space-
and-
timehttps://weibo.com/1727858283/NkBE37ADxhttps://weibo.com/1727858283/NlsDSpPaahttps://weibo.com/1727858283/NlOJfdAkxhttps://weibo.com/1727858283/NeVrw01Yh![](/assets/images/7a2536649ab74508ad4b2a84892032a1.png)