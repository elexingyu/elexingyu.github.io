---
layout: post
title: "Lightspeed发布AI公司和人才趋势报告，工信部确定未来产业创新四大"
date: 2023-09-19
tags: ['AI']
style: huoshui
---



![](/assets/images/ceb617623b324f10b7cc6fdb36a3edbb.jpg)

  

**热点回顾**  

**1**

**Lightspeed 发布 AI 公司和人才趋势报告**

  
  
  
  
  

美国风险投资机构 Lightspeed 近日发布了一份关于全球 3500 多家涉足生成 AI 领域的公司的研究报告，揭示了当前 AI
人才的分布和流动趋势。报告中，Lightspeed 将 8 家拥有顶尖技术人才和碾压优势的公司称为 “八强”，它们分别是：Tome, Character
AI, Anthropic, OpenAI, Hugging Face, Jasper, Stability AI 和 Midjourney。这些公司在
AI 领域展示了强大的实力和创新能力，其中 OpenAI 和 Midjourney 的表现尤为突出。此外，报告还指出了 11 家 “明日之星”
公司，它们在特定领域展示了强大的实力和潜力。报告还分析了这些公司的技术人才背景，发现美国的顶尖大学是主要的人才来源，同时也指出了新的 AI
人才聚集地和潜在的发展趋势。

ref. https://medium.com/lightspeed-venture-partners/eight-ai-startups-winning-
the-race-for-tech-talent-571a18b03642

中文编译: https://mp.weixin.qq.com/s/fLebYLHxMBLQlmLuWnakBg

  
  

  

**2**

**Falcon 180B 登顶 Hugging Face 排行榜，性能直逼 GPT-4**

  
  
  
  
  

阿布扎比技术创新研究所（TII）推出 Falcon 180B，拥有 1800 亿参数，其性能在多项基准测试中均超越了 Llama 2，并与 GPT-4
相媲美。该模型基于亚马逊云机器学习平台 Amazon SageMaker 完成了 3.5 万亿 token 的训练，其参数规模是 Llama 2 的 2.5
倍，而训练所需的计算量是 Llama 2 的 4 倍。Falcon 180B 主要依赖 RefinedWe 数据集进行训练，占总训练数据的
85%。此外，它还包含对话、技术论文和一小部分代码的混合数据。尽管 Falcon 180B 在 Hugging Face
开源大模型榜单上得分最高，但英伟达高级科学家 Jim Fan 对其训练数据中仅包含 5%
的代码表示质疑，认为这限制了其推理能力和工具使用掌握程度。Falcon 180B 还推出了聊天对话模型
Falcon-180B-Chat，现已开放给所有人进行 demo 体验。

模型官网：https://falconllm.tii.ae/index.html

试用模型：https://huggingface.co/spaces/tiiuae/falcon-180b-demo

Huggingface 上的介绍文章：https://huggingface.co/blog/zh/falcon-180b

模型下载：https://huggingface.co/tiiuae/falcon-180B

ref. https://mp.weixin.qq.com/s/CH1HMKDhDmChXjnqod5Wrg

  
  

  

**3**

**Colossal-AI 引领大模型训练新标准**

  
  
  
  
  

2023 年 9 月 4 日，由 ChatGPT 引发的大型模型热潮持续升温。在众多模型中，LLaMA
系列因其基础能力和开放生态而积累了大量用户和实际应用，成为了无数开源模型的基准。但 AIGC 相关企业仍面临关键瓶颈，例如如何降低大型模型如 LLaMA2
的预训练成本，以及如何实际构建这些模型。作为全球最大、最活跃的大型模型开发工具社区，Colossal-AI 为 8 至 512 个 GPUs 提供了革命性的
LLaMA2 训练效率、微调和推理解决方案。70 亿参数的训练可以加速 195%，并提供完全托管的 ML
云平台解决方案，大大降低了大型模型开发和应用的成本。此外，Colossal-AI 的高性能来源于系统优化，如新的异构内存管理系统 Gemini
和高性能操作符 Flash attention 2。

ref. https://www.hpc-ai.tech/blog/70b-llama2-training

项目地址: https://github.com/hpcaitech/ColossalAI

  
  

  

**4**

**工信部确定未来产业创新四大重点方向**

  
  
  
  
  

工业和信息化部近日印发通知，组织开展 2023
年未来产业创新任务揭榜挂帅工作，确定了四大重点方向：元宇宙、人形机器人、脑机接口和通用人工智能。该通知要求各地区和单位围绕这四大方向，聚焦核心基础、重点产品、公共支撑和示范应用等创新任务，以培育掌握关键核心技术的优势单位和突破标志性技术产品为目标，推动新技术和新产品的落地应用。通知还明确了各级工业和信息化主管部门推荐项目的数量限制，并要求推荐单位高度重视此项工作，遵循公开、公平、公正的原则完成推荐工作，同时加大政策、资金和资源的支持力度。

ref. https://www.cnii.com.cn/rmydb/202309/t20230915_504097.html

分析文章: https://finance.eastmoney.com/a/202309132846371489.html

  
  

  

**5**

**腾讯混元大模型正式亮相**

  
  
  
  
  

在 2023 年腾讯全球数字生态大会上，腾讯混元大模型正式亮相，并通过腾讯云对外开放。该模型是腾讯全链路自研的通用大语言模型，拥有超千亿参数规模和超 2
万亿 tokens 的预训练语料，具备强大的中文创作、逻辑推理和任务执行能力。腾讯混元大模型已与超过 50
个腾讯业务和产品接入测试，取得初步效果。该模型将作为腾讯云 MaaS 服务的底座，客户可以直接通过 API
调用或构建专属应用。腾讯集团高级执行副总裁汤道生强调，大模型将成为下一轮数字化发展的核心动力。该模型自研技术包括机器学习框架
Angel，提高训练和推理速度，以及优化预训练算法和策略，降低 “幻觉” 现象。腾讯混元大模型在多项评测中表现优异，特别是在中文理解和处理超长文本方面。

ref. https://mp.weixin.qq.com/s/Jw7pUn4BQpKnrAnKL34Stw

  
  

  

**6**

**百度智能云宣布千帆大模型平台 2.0 全面升级**

  
  
  
  
  

在 2023 百度云智大会上，百度智能云公布了千帆大模型平台的 2.0
全面升级。该平台的月活企业数已接近万家，服务于金融、制造、能源、政务、交通等多个行业，涵盖超过 400
个业务场景。此次升级重点增强了大模型的中文理解和生成能力，如 LIama2
的国外大模型现在也能实现出色的中文对话效果。此外，训练和推理性能也得到了显著提升。数据集方面，平台预置了 41
个具有行业特色的数据集，用户可以轻松完成微调。此外，千帆平台还进一步丰富了其工具链，使其更加轻量化和敏捷。算力服务也得到了升级，大模型的训练效率显著提高。

ref. https://www.pingwest.com/w/287841

  
  

  

**2**  
** 本周精选  **  

  

**GoT 思维图：推理质量提升 62%，**

**成本下降 31%**

**1**

  

苏黎世联邦理工大学和华沙理工大学的研究人员共同提出了一个全新的大型语言模型 (LLM) 思维框架 ——GoT（Graph of
Thoughts）。该框架通过将 LLM 生成的信息建模为图，实现了在推理质量和速度上超越现有的思维链 (CoT) 和思维树 (ToT) 等方法。GoT
将信息单元（LLM thoughts）作为图的顶点，顶点间的依赖关系作为图的边，可以将任意的 LLM
思维组合成协同结果，提取出整个思维网络的本质或使用反馈回路来增强思维。实验证明，GoT 在不同任务上提供了优于现有技术的优势。例如，与 ToT
相比，排序任务的质量提高了 62%，同时成本降低了 31%。研究人员认为，GoT 可以使 LLM
推理更接近人类的思维和大脑推理机制，因为二者都在内部形成了复杂的网络结构。

论文链接：https://arxiv.org/pdf/2308.09687.pdf

ref. https://mp.weixin.qq.com/s/eWlms4IxTd4wzka4V7Gu6w

  

**复旦 NLP 团队发表**

**​大模型 Agent 综述文章**

**2**

  

复旦大学自然语言处理团队（FudanNLP）发布了一份关于 LLM-based Agents 的综述论文，长达 86 页，引用超过 600
篇参考文献，全面探讨了基于大型语言模型的智能代理的现状和未来。该综述从 AI Agent
的历史出发，深入探讨了智能代理的背景、构成、应用场景和备受关注的代理社会。

智能代理的构成包括三个核心部分：控制端、感知端和行动端。控制端主要由大型语言模型构成，负责信息处理和决策制定；感知端则拓展了智能代理的感知空间，包括文本、视觉和听觉等多模态领域；行动端则赋予代理具身能力和使用工具的能力，使其能够更好地适应环境变化和与环境互动。

论文还详细探讨了智能代理的多种应用场景，包括单代理场景和多代理场景，以及人机交互场景，展示了 LLM-based Agents
在各个方面的强大潜力和应用前景。通过深入剖析智能代理的各个方面，论文为相关领域的未来发展提供了重要的参考价值。

论文链接：https://arxiv.org/pdf/2309.07864.pdf

LLM-based Agent 论文列表：https://github.com/WooooDyy/LLM-Agent-Paper-List

ref. https://mp.weixin.qq.com/s/eWlms4IxTd4wzka4V7Gu6w

  

**腾讯 AI Lab 深度探讨大模型幻觉**

**3**

  

腾讯 AI Lab
联合多家学术机构发布了一份大模型幻觉问题的综述，全面探讨了幻觉的评估、溯源和缓解方法。幻觉问题是当前大模型落地的一个重要障碍，主要表现为与用户输入、已生成上下文或事实知识冲突的幻觉。综述指出，大模型时代的幻觉问题与传统幻觉有所不同，包括数据来源的海量性和模型的通用性等方面。目前的研究主要集中在事实冲突类型的幻觉上，探索了多种评估基准和指标。综述还深入探讨了幻觉的来源，包括大模型的高估自身能力和生成过程中的问题等。为缓解幻觉问题，研究者提出了多种策略，涵盖大模型的整个生命周期，从预训练到推理阶段。综述最后指出，大模型幻觉问题的研究还面临多方面的挑战和新的研究方向，包括可靠的评估、多语言和跨语言幻觉、多模态幻觉等。

ref. https://mp.weixin.qq.com/s/iAwQmGxzJdVc5YdRpA2wcw

  

**谷歌验证 AI 标注可替代**

**人类进行 RLHF**

**4**

  

谷歌最新研究验证了 AI 标注（RLAIF）可以替代人类反馈强化学习（RLHF）来改进大型语言模型，如 ChatGPT 和 Bard。RLHF
是目前大型语言模型训练的核心方法，其中人类通过评估 AI 输出的质量来提供反馈，但这涉及大量努力和暴露于有害内容的风险。RLAIF
提供了一个自我循环的解决方案，不再依赖人类反馈。

谷歌的研究团队使用了一个大型语言模型来标注两个候选摘要的偏好，然后根据这些标注来训练一个奖励模型，最后利用奖励模型进行强化学习微调策略模型。这个过程包括了多个步骤，如解决位置偏差、引入思维链推理等，以提高与人类偏好的一致性。

通过实验，研究人员发现 RLAIF 可以产生与 RLHF 相当的改进效果，胜率为 50%，即人类评估者在 71% 的情况下更喜欢 RLAIF
生成的摘要，而在 73% 的情况下更喜欢 RLHF 生成的摘要。这表明 RLAIF 是一个可行的替代方案，不再需要大规模的人类标注数据。

谷歌的这项研究打开了一个新的方向，即通过 AI
自我改进来提高模型的性能，而不是依赖人类的反馈。但研究也指出，这项技术还有其局限性，包括其目前只适用于总结任务，而其在其他任务上的泛化能力还有待验证。

论文地址：https://arxiv.org/abs/2309.00267

ref. https://mp.weixin.qq.com/s/IeYBx2vvV4SzBc3G2B-D7Q

  

![](/assets/images/9343e9dfff5a4912856fe76217222c29.png)

欢迎加入阳志平老师创办的「玩转GPT」知识星球，了解更多前沿论文、使用技巧、原创产品，与 2100+ 成员一起碰撞无限创意！

**👇 加入知识星球，一起玩转GPT！**

![](/assets/images/67c8bec476ed41ef9929ef8bf152e6cb.jpg)
