---
layout: post
title: "AI意识测试专家施奈德：有意识的超级智能，或将剥削人类"
date: 2024-06-11
tags: ['AI', '教程']
style: huoshui
---

![](/assets/images/72a0a76e5ac24168879e2b9cb9f51785.png)

作者：Susan Schneider

来源：Edge.org

编译：活水智能

  

**编者按**

> 随着人工智能（以下简称“AI”）技术的进步，是否能创造出拥有意识的超级智能体？如何测试AI是否拥有意识？
>
>  
>
>
> 本文是Edge.org对苏珊·施奈德（Susan Schneider）教授的采访稿，探讨了大脑、意识及AI之间的复杂关系。  
>
>
>  
>
>
> 施奈德教授是一位哲学家和人工智能专家，专注于心灵哲学、人工智能哲学和认知科学。她的研究集中在人工智能与意识的交叉点，她参与了许多关于 AI
> 和意识的前沿项目，例如在普林斯顿高级研究院开发 AI 意识测试。
>
>  
>
>
> 这篇文章虽然发表在2019年，但在当前AI快速发展的时期，对思考AI对自己工作、生活的影响，AI智能体，依然提供了独特视角。
>
>  
>
>
> 文章较长，请收藏慢慢看～

![](/assets/images/0cffff641fdf451689a6f2d43f5d6359.png)

我一直在思考大脑的基本性质和自我存在的本质。

最近，我开始将这些问题与新兴技术联系起来。特别是，我一直在思考大脑的未来，以及AI技术可能如何重塑人类的大脑并创造出合成的大脑。

随着AI变得越来越复杂，我非常感兴趣的一件事是，我们可能创造出的生物是否能有意识的体验。

意识体验是你精神生活的感觉质量。当你看到夕阳的丰富色彩或闻到早晨咖啡的香气时，你正在有意识的体验。

意识体验对你来说非常熟悉。事实上你清醒生活的每一刻都是一个有意识的存在。

如果我们拥有了通用人工智能，这种智能能够灵活地在不同领域之间连接思想，甚至可能有类似感官体验的东西。

我想知道的是它是否会有意识，或者它是否只是在黑暗中计算——从计算的角度进行视觉识别任务，思考复杂的思想，但并非真正有意识。

与许多哲学家，特别是媒体和超人类主义者中的许多人不同，我倾向于对机器意识采取观望的态度。

首先我拒绝完全怀疑的立场。过去有一些知名的哲学家对机器ju yo意识持怀疑态度，如著名哲学家约翰·塞尔。

但我认为现在还为时过早。是否会有意识的机器，将由许多变量决定。

另一方面我们必须问，根据自然法则，是否能创造出有意识的机器。我们不知道意识是否可以在其他基质中实现。

我们不知道最快的微芯片会是什么，所以我们不知道通用人工智能会由什么构成。因此，直到那时，我们很难说高度智能的东西是否会有意识。

1  

现在最安全的做法可能是在复杂智能和意识之间划清界限。我们需要做的是保持开放的心态，并怀疑。就我们目前所知，最复杂的智能可能不会有意识。有很多问题，不仅仅是涉及技术本质的问题，将决定是否可能出现有意识的机器。

假设原则上可以构造一个有意识的人工智能，谁会想要这么做呢？想想现在关于安卓权利的辩论。

假设所有那些被设计来照顾人们家庭和照顾老人的日本机器人都有意识。当他们是有意识的生物时，强迫他们为他人工作，这不就像奴隶制吗？

我不确定AI公司是否会想要生产出有意识的生物。

事实上他们可能决定将意识工程化。当然，我们不知道意识是否可以被工程化进入或退出机器。就我们目前所知，可能与自然法则不兼容。

相反，它可能是复杂计算的不可避免的副产品，然后我们将不得不非常关心安卓和其他AI的权利。

如果机器最终被证明有意识，我们不仅会了解机器的大脑，我们可能还会了解我们自己的大脑。

我们可以更多地了解意识体验的性质，这可能会让我们作为一个文化体开始反思作为一个有意识的存在是什么意思。

人类将不再特殊，因为它们有能力进行智力思考。我们将与那些甚至不是由我们同样的物质构成的合成生物分享这个位置。这可能会是人类的一次非常谦卑的体验。

随着文明的智能化程度提高，它们可能会变得生物化。因此，合成智能可能会成为成功的技术文明的自然产物。在相对短的时间内，我们已经成功地创造出了有趣且复杂的人工智能。

我们现在正在将人工智能用于构建神经假体，以增强人类大脑。

我们已经看到像雷·库兹魏尔和埃隆·马斯克这样的科技大咖谈论使用脑芯片增强人类智能——不仅帮助患有大脑疾病的人，也帮助人们活得更长久，变得更聪明。

![](/assets/images/2937ee2254f64908a6963b6b0ef4feae.png)

脑机接口（图来源：healththoroughfare.com）

可能的情况是，宇宙中的文明变得生物化，并增强了他们的智能，成为了合成生物。

从某种意义上说，人工智能可能是成功的技术文明的自然产物。

当然，这并不是说宇宙中充满了生命。可能并非如此。这是一个实证问题，尽管我在NASA的许多同事对此持乐观态度。

这也并不是说，即使其他星球有生命，生命也会变得技术化。我们仍然不清楚生命本身能否继续进步并在技术成熟后存在的可能性有多大。

## 2

我开始我的学术生涯是作为一名经济学家，然后偶然进入了唐纳德·戴维森这位杰出的哲学家的课堂。

我发现我喜欢英美哲学，并开始与杰瑞·福多尔一起工作，他是一位著名的心灵哲学家，也是现在深度学习理念的批评者。

福多尔和我会花几个小时讨论人工智能的范围和限制。我不同意他对这些早期深度学习观点的看法。我不认为它们像他所说的那样不可能。

当时，这些被称为“连接主义”。他声称大脑不是计算模拟的，当人工智能达到通用人工智能的水平时，可能不会成功，因为人类大脑有一些特殊的非计算特性。

具体来说，他指的是“中枢神经系统”，我们可能会认为这些是通用的大脑区域，超越了高度分隔的心理功能——这些是产生人类创造力和认知的来源。

我坚持认为大脑从头到尾都是计算的。例如，有关工作记忆和注意力的成功理论涉及到领域通用的功能。在与福多尔合作时，我发现我阅读了大量的计算神经科学。

![](/assets/images/7a1b0591d5054b4885838f0f08515254.png)

我主张大脑可能是一个混合系统，可以用你在计算神经科学中看到的神经网络方法来描述。

但其中包含了你在认知心理学中看到的这些更高级别的描述，这些描述参考了像杰瑞·福多尔这样的人所引用的思考模式——符号语言，既认为大脑是一个符号处理设备，根据规则操纵符号。

与福多尔讨论深度学习系统应该会很有趣。我想他对这些系统进一步发展成为一些人所说的人工通用智能的可能性仍然会持怀疑态度。

我并不是在暗示现有的资源能够产生如此复杂的东西。

然而，随着所有的资金投入人工智能，所有的成功案例，计算速度年复一年的提高，总是能找到更好更快的微芯片，量子计算被严肃地开发的可能性——所有这些都强烈支持人工智能将逐步变得越来越好。

与此同时，我们可以查看神经科学的不同领域，如计算神经科学的资源，并借鉴大脑的工作方式。我们可以从大脑逆向工程AI，只要我们需要这样做。

3  

当我开始思考Deep Mind的成功故事，例如特定领域的系统，我开始更加乐观地认为，随着对AI技术的所有重视和可用的改进技术，将会创造出更复杂的AI。

我们不仅会创造出智能机器人，我们还会将AI放入我们的大脑中，改变人类大脑的形状。然后我开始担心这如何改变社会。

我在当前关于大脑性质的讨论中看到了许多误解，比如假设如果我们创造出复杂的AI，它必然会有意识。

还有这样的观点，我们应该“与AI融合”——为了让人类能跟上AI的发展，不致于屈服于敌对的超级智能AI或基于AI的技术失业，我们需要用AI技术增强我们自己的大脑。

让我担忧的一件事是，我不认为AI公司应该解决涉及大脑形状的问题。大脑的未来应该是由文化决定和个人决定。

![](/assets/images/2225f6bc9cf6468ab1405ab0eaa185f7.jpg)

这里涉及的许多问题都是经典的哲学问题，没有简单的解决方案。

例如，元理学领域关于人的性质的理论。假设你添加一个微芯片来增强你的工作记忆，然后几年后你添加另一个微芯片来将自己与互联网集成，你只是不断地添加增强功能。

在什么时候你还是你自己呢？当你考虑增强大脑能力时，目标是改善你的生活——让你更聪明，或者更快乐，甚至可能活得更长，或者随着年龄的增长大脑更敏锐。

但如果这些增强以如此剧烈的方式改变我们，以至于我们不再是同一个人呢？

这些问题是像休谟、洛克、尼采和帕菲特这样的哲学家在关于人的性质的辩论中思考了多年的问题。

![](/assets/images/4a6d0eeceb1b4591a6512585709a5595.png)

现在我们有可能塑造我们自己的大脑，我相信我们需要与这些关于自我性质的经典哲学立场进行对话。

我对技术的痴迷深感担忧。

我认为自己是一个技术进步主义者，我希望看到技术被用来改善人类的生活，但我们需要对这种与AI融合的想法，甚至我们周围随时都有物联网的想法持谨慎态度。

随着这些神经增强技术的发展，我们现在需要做的是进行公开对话。所有的利益相关者都需要参与进来，从研究这些技术的人，到政策制定者，再到普通人，特别是年轻人，这样他们在做出增强大脑能力决策时，将能够进行更多思考。

在这里，关于自我性质和意识性质的经典哲学问题就显得尤为重要。

大公司的AI伦理委员会很重要，但从某种意义上说，这就像狐狸看守鸡窝。我们将如何在使用AI技术创造合成大脑和增强人类大脑方面，拥有一个积极的未来的唯一方式，就是将这些问题直接带给公众，这就是我非常关心公众参与并确保所有利益相关者参与的原因。

下个月我将成为国会图书馆的杰出学者，所以我可以将这些问题带到华盛顿特区。

我希望尽管许多科技公司领导者太忙，无暇深入思考一些基础的哲学问题，公众本身能够参与这个话题。

## 4

我们如何判断一台机器是否有意识呢？

我建议我们不能仅仅假设复杂的AI会有意识。此外，可能只有某些AI程序或某些基质，某些类型的微芯片才能发展出意识，而其他的则不能。

就我们目前所知，也许基于硅的系统可以有意识，但使用碳纳米管的系统则不能。我们还不知道。这是一个实证问题。所以有测试会很有用。

棘手的部分是，即使在今天，我们也不能确切地知道深度学习系统在做什么。AI的黑箱问题是，我们如何能知道深度学习系统中的计算是什么，即使在它们今天的初级复杂性水平。

确定机器的意识，最有效的方式是下面两种。

首先要做的是进行一种基于行为的测试。我在高级研究所与天体物理学家和系外行星专家埃德温·特纳一起开发了这种测试。

这是一个简单的测试。我们作为有意识的生物的一个非常显著的事实是，我们可以理解涉及大脑的思想实验。

当你还是个孩子的时候，你可能看过《怪异星期五》，这是一个母女交换身体的案例。为什么这对我们来说是有意义的呢？

这对我们有意义，因为我们可以想象大脑离开身体。现在，我并不是说大脑确实离开了身体，但我们至少可以大致设想涉及来世、转世、哲学思想实验的情况。

我们需要做的就是，寻找能够想象这些情况的AI。现在有一个反对意见，一个很好的反对意见，那就是我们可以只有编程领域让AI表现得像有意识。今天已经有AI会和你交谈，表现得像是有精神生活。

考虑一下汉森机器人公司的索菲亚。她会和你交谈，媒体甚至会像她是一个有意识的生物一样谈论她。我相信她甚至在沙特阿拉伯被提供了公民身份，这很有趣。

![](/assets/images/26ee903b551b451e95b2f4001697709d.png)

索菲亚（来源：汉森公司官网）

我们需要做的是将人工智能限制在一个"盒子"中，以判断它是否具有意识。这是AI安全研究中的一种策略，用于在研发阶段学习系统能力时，防止AI获取关于世界的知识或在世界中行动。

在这个阶段，如果你不给人工智能提供关于神经科学和人类意识的知识，而你在探测它的意识体验时看到异常行为，给它提供思考实验并观察它的反应。简单地问它："你能想象在你的部件被摧毁后还存在吗？"

特纳和我设计了几个问题，这是一种针对机器意识的图灵测试，旨在在适当的限制下引发机器的行为，以确保我们不会得到假阳性结果。

话虽如此，我并不认为这个测试是接近机器意识的唯一方式。这是哲学家所说的机器意识的"充分条件"。

所以，如果某物通过了它，我们有理由相信它是有意识的。但是，如果某物没有通过它，其他测试可能会确定它仍然有意识。它可能不适合语言，可能没有自我意识，等等。

我提到我提供了两种方法。

让我谈谈确定机器是否可能有意识的第二种方法，这是一个合理的路径，考虑到现在脑芯片的发展。  

当我们在人脑中负责意识体验的部位使用神经假体或脑芯片时，如果这些芯片成功，如果我们没有注意到意识的缺陷，那么我们有理由相信：由特定基质（比如硅）制成的微芯片，在正确的架构环境中，可能具有意识。

如果我们确定另一种基质，当放入人脑时，不会改变我们的意识体验的质量，当它在我们认为负责意识的大脑区域时，这将是重要的。

这意味着，原则上，我们可能会开发出一种合成意识。我们甚至可能通过逐渐用人工组件替换人脑来实现这一点，直到最后我们有一个完全成熟的AI。

5  

我热爱哲学与科学的交叉点，或者说科学变得模糊，人们必须思考其含义的部分。这样的例子包括物理学中的时空出现理论，他们发现自己在看数学理论，然后从中得出关于时间性质的结论。

像这样的问题涉及到数学或经验考虑和哲学问题之间的微妙平衡。这就是我喜欢介入并参与的地方。

我对我们作为人类能知道的范围和限制有着强烈的兴趣。我们是谦卑的生物，也许当我们开发我们的大脑时，我们会找到一些经典哲学问题的答案。

谁知道呢？如果我们在不仔细思考涉及意识性质或自我性质的问题的情况下发展人工智能技术，人工智能技术可能无法实现开发人员希望它们实现的目标，即改善我们的生活，促进人类的繁荣。

我们必须小心确保，我们知道我们是否正在创造有意识的生物，我们知道是否能够极大地增强我们的大脑与个人的生存相兼容性，否则这些技术将导致对有意识生物的剥削和造成痛苦，而不是改善人们的生活。

我喜欢生活在那种谦卑的空间里，我们在那里碰到了认识论的墙，因为它教会我们人类能理解的范围和限制。

在这个技术创新横扫一切的时代，要记住，总会有一些问题我们无法得到完全确定的答案。

一个很好的例子是，我们是否生活在大脑的“瓶子”里——在计算机模拟中活着。

这些是认识论问题，涉及知识性质的问题，没有简单的答案。

**申明：本文所有权归 Susan Schneider，转载注明出处**
