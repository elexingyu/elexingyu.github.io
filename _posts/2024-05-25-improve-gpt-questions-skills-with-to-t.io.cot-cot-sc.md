---
categories: articles
date: 2024-05-25
layout: post
style: huoshui
tags:
- AI
- 教程
title: ToT、IO、CoT与CoT-SC，提高你向GPT提问的能力
---

![](/assets/images/09573dbe209f429b885e4ae69339984a.png)

作者：猫柳

来源：公众号「自由特质协议」

  

看到一项研究，普林斯顿清华姚班校友提出「思维树ToT」框架，让LLM反复思考，GPT-4推理大幅提升。了解到一个新名词：思维树ToT。

## 什么是思维树ToT？

什么是思维树ToT？

> “思维树”（Tree of
> Thoughts，简称ToT）是一种新型的推理框架，它允许语言模型（LMs）在解决问题的过程中，对多种不同的推理路径进行深入考虑，自我评估选择，并在必要时进行预见或回溯，以做出全局选择。——AskYourPDF

根据文章给出的论文地址，下载源头论文阅读。

论文地址：  
https://arxiv.org/abs/2305.10601

论文提到：

> 最初被设计用于生成文本的语言模型（LMs）的扩展版本，例如 GPT 和 PaLM
> 已经显示出越来越多地执行需要数学、符号、常识和知识推理的任务。也许令人惊讶的是，在所有这些进展背后，仍然是用于生成文本的原始自回归机制，它逐个标记地做出决策，并以从左到右的方式进行。

论文接着说，“通过逐个标记地做出决策，并以从左到右的方式进行的推理框架，是否能通向一般问题的解答呢？”

研究者向关于人类认知的文献中寻找思路。

他们从“双重过程”模型中获得灵感。

“双重模型”指出人类做决策时有两种模式，即系统1与系统2。

  * • 系统1是一种快速的、自动的、无意识的模式；

  * • 系统2是一种缓慢的、深思熟虑的、有意识的模式。

研究者称，LMs基于tokens-level的选择，让人联想起“系统1”。那么，LMs是否也能受惠于更加深思熟虑的“系统2”呢？

以此，他们提出ToT，模拟“系统2”的特点：

  * • 1）提供多种选择而不仅是一种；

  * • 2）评估其当前状态并积极地向前或回溯以做出更全局性的决策。

## 除了ToT，语言模型的其他推理框架

除了ToT，LLMs 解决问题有几种方法：IO、CoT、CoT-SC 推理框架。

什么是 IO、CoT、CoT-SC？

论文提供了一个图，让我们能更直观了解这三个推理框架。

![](/assets/images/b1805fbf33db488881ae0d5e13c5c2e5.webp)

图注：如果将每个矩形框代表一个思想单元，它是一系列连贯的语言序列，作为解决问题的中间步骤。

如果这个图还不能让你明白 IO、CoT、CoT-SC ，我们不妨再邀请 GPT-4 举例说明。

[以下内容来自GPT-4]

  1. 1\. IO（Input-Output）：这是最直接的推理框架，也是最常见的。在这个框架中，模型直接从输入生成输出，没有任何中间步骤。例如，如果你问一个语言模型“今天是星期几？”，模型会直接给出答案，比如“今天是星期一”。

  2. 2\. CoT（Chain of Thoughts）：这个框架比IO复杂一些。在CoT中，模型不是直接从输入生成输出，而是通过一系列的中间步骤（或者说“思维”）来生成输出。这些中间步骤可以帮助模型更好地理解问题，也可以让模型的推理过程更加透明。例如，如果你问一个使用CoT框架的模型“2+2等于多少？”，模型可能会首先生成一个中间步骤，比如“我知道2+2是一个加法问题”，然后再生成输出“2+2等于4”。

  3. 3\. CoT-SC（Chain of Thoughts with Self-Consistency）：这个框架是CoT的一个扩展。在CoT-SC中，模型会生成多个可能的思维链，并选择最一致的输出。这可以帮助模型在面对复杂或模棱两可的问题时，生成更准确的答案。例如，如果你问一个使用CoT-SC框架的模型“一个苹果和两个苹果一共有多少个苹果？”，模型可能会生成多个思维链，比如“一个苹果加上两个苹果等于三个苹果”和“一个苹果和两个苹果一共有三个苹果”。然后，模型会选择这两个思维链中最一致的输出，也就是“三个苹果”。

那么，与IO、CoT、CoT-SC相比，ToT有什么特点呢？

论文中，引用了认知科学之父们 Newell,、Shaw和Simon（即赫伯特·西蒙）等人的经典论文《Report on a general problem
solving program》。文中，Newell et al. 提到：

> 一个真正的问题解决过程涉及到反复利用可用信息来启动探索，进而揭示更多信息，直到最终发现实现解决方案的方法。

A genuine problem-solving process involves the repeated use of available
information to initiate exploration, which discloses, in turn, more
information until a wayto attain the solution is finally discovered.—— Newell
et al.

认知科学之父们提出，“人们通过组合问题空间进行搜索——一棵树，其中节点表示部分解决方案，分支对应修改它们的运算符。选择哪个分支是由启发式确定的，这有助于导航问题空间并引导问题求解者走向解决方案。”

解决问题的思路与之类似。

ToT将任何问题框架化为一个搜索树，在其中每个节点都是一个状态，表示具有输入和迄今为止所做思考序列的部分解答。

规划 ToT 解决问题思路，需要回答四个问题：

  * • 1.如何将中间过程分解成思考步骤；

  * • 2.如何从每个状态生成潜在的思考；

  * • 3.如何启发式地评估状态；

  * • 4.使用什么搜索算法。

由此，研究者提出四个关键步骤：

  * • 1、思维分解。ToT利用问题的属性来设计和分解中间的思维步骤。

  * • 2、思维生成器。通过给定树状态，通过2种策略来为下一个思维步骤生成k个候选者。

  * • 2.1 从一个 CoT 提示采样思维

  * • 2.2 使用「proposal prompt」按顺序提出想法

  * • 3、状态评估器。给定不同状态的前沿，状态评估器评估它们解决问题的进展，作为搜索算法的启发式算法，以确定哪些状态需要继续探索，以及以何种顺序探索。

  * • 4、搜索算法。在ToT框架内，可以根据树结构插入和使用不同的搜索算法。例如广度优先搜索（BFS）和深度优先搜索(DFS)。

论文还提出了三个任务用于测试，即24点（Game of 24）、创意写作和迷你填字游戏。具体实例请参考论文。（我有些没读懂）

## 如何向GPT发出指令，让它按照不同推理框架回答？

以一个生活例子“如何煮一壶咖啡”为例。

以下答案来自GPT-4。

  1. 1\. IO（Input-Output）：在这个框架下，你可以直接问：“如何煮一壶咖啡？”GPT-4会直接给出答案，比如：“首先，将咖啡豆磨成粉。然后，将咖啡粉放入咖啡机中。接着，加入适量的水。最后，按下咖啡机的启动按钮。”

  2. 2\. CoT（Chain of Thoughts）：在这个框架下，你可以问：“我想煮一壶咖啡，你能帮我规划一下步骤吗？”GPT-4可能会生成一系列的思维步骤，比如：“首先，我们需要准备咖啡豆和咖啡机。然后，我们需要将咖啡豆磨成粉。接下来，我们需要将咖啡粉放入咖啡机中。最后，我们需要加入适量的水，然后启动咖啡机。”

  3. 3\. CoT-SC（Chain of Thoughts with Self-Consistency）：在这个框架下，你可以问：“我想煮一壶咖啡，你能帮我规划一下步骤，并确保每个步骤都是一致的吗？”GPT-4可能会生成多个思维链，并选择最一致的输出。例如，它可能会生成两个思维链：“首先，我们需要准备咖啡豆和咖啡机。然后，我们需要将咖啡豆磨成粉。接下来，我们需要将咖啡粉放入咖啡机中。最后，我们需要加入适量的水，然后启动咖啡机。” 以及 “首先，我们需要准备咖啡豆和咖啡机。然后，我们需要将咖啡豆磨成粉。接下来，我们需要将咖啡粉放入咖啡机中。最后，我们需要加入适量的水，然后启动咖啡机。”因为这两个思维链是一致的，所以GPT-4会选择它们作为输出。

  4. 4\. ToT（Tree of Thoughts）：在这个框架下，你可以问：“我想煮一壶咖啡，你能帮我考虑一下所有可能的步骤，并选择最好的步骤吗？”GPT-4可能会生成多种可能的思维路径，比如使用不同的咖啡豆，使用不同的咖啡机，或者使用不同的煮咖啡方法。然后，GPT-4会评估每个路径的可能性，并选择最有可能的路径。例如，它可能会选择这样的路径：“首先，我们需要选择高质量的咖啡豆。然后，我们需要使用专业的咖啡机。接下来，我们需要使用正确的煮咖啡方法，比如法式压滤法。最后，我们需要在正确的时间内煮制咖啡，以保证咖啡的味道。”

## 与GPT对话的其他技巧

与GPT更好地对话，有一个关键，是如何更好地提问。上面例子给出了示例，通过指令让GPT采用不同的推理路线。

  * • IO式：直接提问“如何煮一壶咖啡？”

  * • CoT式：“我想煮一壶咖啡，你能帮我规划一下步骤吗？”

  * • 或者更常见的：“让我们思考一下”、“让我们谈谈”、“让我们讨论”

  * • CoT-SC式：“我想煮一壶咖啡，你能帮我规划一下步骤，并确保每个步骤都是一致的吗？”

  * • ToT 式：“我想煮一壶咖啡，你能帮我考虑一下所有可能的步骤，并选择最好的步骤吗？”

除此，还有一些常用的提问技巧，如零/一/少样本提示、角色扮演提示。

零/一/少样本提示，即不输入例子、输入一个例子或输入少量例子向GPT提问。

  * • 零样本（Zero-Shot）提示示例：

> 为一门新的课程编写产品描述

  * • 一样本（One-Shot）提示示例：

> 按照[该标题]，生成十个相似的标题

  * • 少量样本（Few-Shot）提示示例：

> 按照[例子1]、[例子2]、[例子3]，为这个产品生成评论

角色扮演提示，即是让GPT扮演特定角色输出答案。

例如，”你是一名阅读领域专家，你认为什么是结构阅读法？“

在没有输入语料的情况下，关于“什么是结构阅读”，GPT会生成一个普遍的解释。

如：“结构阅读涉及到理解整本书的总体结构。这包括识别写作中的模式，理解作者的写作风格，以及理解书籍的整体流程。这种技巧对于快速把握书的主要思想和深入理解作者的意图很有用。在阅读熟悉主题的书籍时，这种技巧尤其有用，因为读者可以使用他们已有的知识来更好地理解书籍的结构。同时，建议好的写作往往源于反复阅读，这表明这种技巧可能对作家有益。”

在没有指示GPT扮演专家的时候，他根据自己已有的知识（语料库里储存的知识）做出他认为合理的推断。

一旦你让GPT扮演不同领域的专家，他就能带有某个领域色彩，调整回答。就像人类不同专家，他们会基于自己知识体系，做出符合其领域身份的回答。

例如，让GPT分别扮演阅读专家、心理学研究者和作家，回答“你认为结构阅读是一种怎样的阅读方法？”

GPT-4的回答：

【作为阅读专家】

结构阅读是一种有效的阅读方法，其主要目标是理解和掌握文本的整体结构和组织方式。在这种阅读方法中，读者将更加关注书籍或文章的整体布局、章节安排、主题和子主题的组织方式，以及各个部分之间的逻辑关系。

为了进行结构阅读，读者可能需要首先浏览整本书或整篇文章，注意其标题、小标题、章节标题、图表、摘要、结论等部分，以了解其主要内容和组织结构。然后，读者可以根据这个结构进行更深入的阅读，理解各个部分如何支持整体的主题或论点。

结构阅读的好处是，它可以帮助读者更好地理解和记忆文本的内容。通过理解文本的结构，读者可以更容易地把握作者的观点和论据，而不是仅仅记住一些零散的信息。此外，结构阅读也有助于读者更有效地筛选和吸收信息，因为他们可以根据对结构的理解，决定哪些部分是他们需要重点阅读和理解的。

【作为心理学领域的研究者】

结构阅读是一种从心理学角度来看具有很多优点的阅读方法。在这种阅读方式中，读者首先试图理解文章或书籍的整体结构，包括其主题、子主题、论点和证据等。这种方法强调对文章或书籍的整体理解，而不仅仅是对其各个部分的理解。

从认知心理学的角度来看，结构阅读有助于改善信息的组织和记忆。研究表明，我们的大脑更容易记住那些有逻辑结构和组织的信息，而不是无序的、随机的信息。通过了解文本的结构，读者可以将新信息更有效地与他们已有的知识结构相连接，从而改善记忆和理解。

此外，结构阅读也有助于读者更有效地进行批判性思考。通过理解文本的结构，读者可以更好地评估作者的论点，理解其证据的强度，以及识别任何可能存在的逻辑漏洞或偏见。

结构阅读的一种常见技术是”预读”或”浏览”，即在深入阅读文本之前，先快速查看标题、小标题、图表、摘要和结论等部分。这种技术可以帮助读者形成对文本的初步理解，为深入阅读做好准备。

【作为作家】

作家的视角对于阅读技巧可能会有一些不同的侧重点。在阅读中，作家不仅需要关注内容，还需要对文章或书籍的整体结构有深入的理解。这种理解可以帮助他们在自己的创作中更好地构建情节，塑造角色，或者提炼主题。

所以，从作家的角度看，结构阅读可能更多地关注以下几个方面：

  1. 1\. 情节结构：作家可能会注意到故事或论述的整体框架，包括它是如何开始的，中间发生了什么，以及最后是如何结束的。这对于理解并最终创作出有吸引力的故事情节十分重要。

  2. 2\. 角色发展：作家可能会通过结构阅读来理解角色如何随着故事的进展而发展。这种理解可以帮助他们在自己的作品中创造出深度和复杂性的角色。

  3. 3\. 主题和象征：通过观察书籍或文章的整体结构，作家可以更深入地理解作者是如何通过各种元素（如象征，隐喻等）来表达主题的。

总的来说，结构阅读对作家来说，是一个了解和学习其他作家如何构建他们的作品的重要工具，可以帮助他们在自己的创作中更好地使用这些技巧和策略。

\-----

是不是感受到不同的答案差异呢？

因此，让GPT扮演不同的角色，既有利也有弊。毕竟我们人人都有恨不得专家闭嘴的时刻。

## 小 结

源头论文请移步下载PDF阅读：

https://arxiv.org/abs/2305.10601

认知科学果然很底层。


## 推荐阅读

  • [Nature最新研究，AI模型比酿酒师更懂啤酒风味](http://mp.weixin.qq.com/s?__biz=Mzk0OTY0NzM1Ng==&mid=2247485590&idx=1&sn=9f00db453841c95bd21f967fd4f31514&chksm=c3546a05f423e313dbfce7977d231c1092d580550132b2c2bd8bc82d6002c00db370ded470a4&scene=21#wechat_redirect)

  • [最全盘点：人类历史上所有文本数据总量](http://mp.weixin.qq.com/s?__biz=Mzk0OTY0NzM1Ng==&mid=2247485448&idx=1&sn=149c4683bd8d1d2f75b444b900503823&chksm=c3546a9bf423e38dcb031eabe5d3f9002714ac13eb29d741b47d3aecde4ae3a0a88a9ce8232e&scene=21#wechat_redirect)

  • [首次公开！我们用42天创造了8个大模型相关产品](http://mp.weixin.qq.com/s?__biz=Mzk0OTY0NzM1Ng==&mid=2247484889&idx=1&sn=280ec964af5c3cfb05b091fc68c1a859&chksm=c354674af423ee5c56938a47d08685a81e311a36e3b7a6b8e82b6bd5bb5972d1004c7c405abb&scene=21#wechat_redirect)


* * *